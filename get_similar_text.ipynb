{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     /home/ilana/nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from nltk.data import find\n",
    "nltk.download(\"word2vec_sample\")\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_vector = word_vectors[word_list.index(\"happy\")].toarray()[0]\n",
    "legislation_vector = word_vectors[word_list.index(\"legislation\")].toarray()[0]\n",
    "\n",
    "\n",
    "def get_top_10_closest_words(word,word_vectors,word_list):\n",
    "    word_index = word_list.index(word)\n",
    "    word_vector = word_vectors[word_index]\n",
    "    if word_vector.shape[0] != 1:\n",
    "        word_vector = [word_vector]\n",
    "    comparisons = cosine_similarity(word_vector,word_vectors)\n",
    "    for index in reversed(np.argsort(comparisons[0])[-10:]):\n",
    "        print(word_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similarity(similarity_dict1,similarity_dict2):\n",
    "    X = [similarity_dict1[word_pair] for word_pair in similarity_dict2]\n",
    "    Y = [similarity_dict2[word_pair] for word_pair in similarity_dict1]\n",
    "    return pearsonr(X,Y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    '''tokenize text into list of lists, sents and words, remove stopwords'''\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    sents = sent_tokenize(text)\n",
    "    result = []\n",
    "    for sent in sents:\n",
    "        word_tokenized = word_tokenize(sent)\n",
    "        result.append([w for w in word_tokenized if not w in stop_words] )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change in topic\n",
    "def get_cosine_similarities(sents, word_vectors, k): # k = len(sents)\n",
    "    \n",
    "    ''' returns an array of similarities of len(sents), corresponding to the cosine of the\n",
    "    vectors produced by summing the embeddings of words in the k sentences of either side of \n",
    "    each sentence boundary, with the first and last k similarities set to -1\n",
    "    ---------------------\n",
    "    sents - list, word tokenized'''\n",
    "    \n",
    "    cosine_similarities = [-1]*k\n",
    "    #your code here\n",
    "    sents_vec = [] #one embedding per sentence\n",
    "    for sent in sents:\n",
    "        sent_vec = []\n",
    "        for word in sent:\n",
    "            if word in word2vec_model:\n",
    "                word_vec = word2vec_model.wv[word]\n",
    "                sent_vec.append(word_vec) # add each word embedding per sent\n",
    "        sents_vec.append(np.sum(sent_vec, axis = 0)) # sum over columns\n",
    "   \n",
    "    for i in range(len(sents_vec) - k):\n",
    "        if 2*k+i <= len(sents_vec)-1:\n",
    "            cluster_1 = np.sum(sents_vec[i:k+i], axis = 0)\n",
    "            cluster_2 = np.sum(sents_vec[(k + i):(k + i)+k], axis = 0)\n",
    "            cosine_similarities.append(1 - cosine(cluster_1, cluster_2))\n",
    "\n",
    "    for i in range(k):\n",
    "        cosine_similarities.append(-1)\n",
    "    \n",
    "    return np.array(cosine_similarities)\n",
    "\n",
    "# cosine_similarities = get_cosine_similarities(sents,word2vec_model,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change in topic\n",
    "def get_text_embedding(sents, word_vectors): # k = len(sents)\n",
    "    \n",
    "    ''' returns an word embeddings of len(sents), produced by summing the embeddings of words \n",
    "    in each sentences\n",
    "    ---------------------\n",
    "    sents - list, word tokenized\n",
    "    word_vectors - word2vec model'''\n",
    "    \n",
    "    #your code here\n",
    "    sents_vec = [] #one embedding per sentence\n",
    "    for sent in sents:\n",
    "        sent_vec = []\n",
    "        for word in sent:\n",
    "            if word in word2vec_model:\n",
    "                word_vec = word2vec_model.wv[word]\n",
    "                sent_vec.append(word_vec) # add each word embedding per sent\n",
    "        sents_vec.append(np.sum(sent_vec, axis = 0)) # sum over columns\n",
    "   \n",
    "    result = np.sum(sents_vec, axis = 0)\n",
    "    \n",
    "    return result.flatten()\n",
    "\n",
    "# cosine_similarities = get_cosine_similarities(sents,word2vec_model,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = preprocess(\"Hi, this is a test. Whats up. Im tired as heck.\")\n",
    "get_text_embedding(test, word2vec_model).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_docs(all_inputs_archive):\n",
    "    ''' Given all documented user cases dict, return dict of doc_id to word-tokenized sents\n",
    "    ------------\n",
    "    all_inputs_archive: dictionary where key = user_id, value = raw text'''\n",
    "    result = dict()\n",
    "    for doc, text in all_inputs_archive.items():\n",
    "        result[doc] = preprocess(text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text and generate single vector for text\n",
    "\n",
    "def get_similarities(input_text_vec, archive_preprocessed_dict):\n",
    "    ''' Takes in embedding of input text (dense matrix) and preprocessed dictionary of user_id: tokenized_text.\n",
    "    Returns dictionary of cosine similaries where key is user_id, output is cosine similarity between archive text and input text'''\n",
    "    text_similarities = dict()\n",
    "    for usr_id, text in archive_processed.items():\n",
    "        text_vec = get_text_embedding(text, word2vec_model)\n",
    "        text_similarities[usr_id] = 1 - cosine(input_vec, text_vec)\n",
    "    return text_similarities\n",
    "\n",
    "def output_most_similar_text(similarities_dict, archive_df):\n",
    "    '''Given dictionary mapping similarities to cosine_similarity\n",
    "    and data frame of full archive text, return csv file with original fields and similarity for most similar text.\n",
    "    -------------------\n",
    "    similarities_dict: dict, user_id:cos_similarity\n",
    "    archive_df: pandas DataFrame of archive data'''\n",
    "    max_sim = 0\n",
    "    best_usr = \"\"\n",
    "    for key, val in similarities_dict.items():\n",
    "        if val > max_sim:\n",
    "            max_sim = val\n",
    "            best_usr = key\n",
    "#     output[best_usr] =  max_sim\n",
    "    result = archive_df[archive_df[\"Unique ID\"] == best_usr]\n",
    "    result[\"similarity\"] = max_sim\n",
    "    \n",
    "    return result.to_csv(r'../Code/results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df = pd.read_csv(\"../Data/archive.csv\")\n",
    "archive_df.dropna(inplace = True)\n",
    "keys = archive_df['Unique ID'].iloc[1:]\n",
    "vals = archive_df['Details'].iloc[1:]\n",
    "archive_dict  =  dict(zip(keys, vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After disagreeing with my manager, I was taken aside and given a severance offer, while my male coworker who agreed with me was kept on the team'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df[archive_df[\"Unique ID\"] == 0].loc[:,\"Details\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "input_text = archive_df['Details'][0]                            \n",
    "sents_input = preprocess(input_text)\n",
    "input_vec = get_text_embedding(sents_input, word2vec_model)\n",
    "archive_processed = get_tokenized_docs(archive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vec.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n",
      "/home/ilana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "similarities_dict = get_similarities(input_vec, archive_processed)\n",
    "output_most_similar_text(similarities_dict, archive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'In team meetings where my coworkers and I share anecdotes about our personal lives, I mentioned my preference for they/them pronouns. My manager was visibly uncomfortable, and a few weeks later I was transferred to a different team, to a role that is less senior.',\n",
       " 2: 'After 5 years working at my bank, consistently earning positive performance reviews and being promised a raise by my boss, my newer Canadian co-worker was promoted before me. My boss said it was because a Canadian would be better suited for this position than me.',\n",
       " 3: 'I was unable to claim my insurance reimbursement when the human resources representative learned that I was First Nations, claiming that I already get too many handouts because of my First Nations status.',\n",
       " 4: 'The head cook and male kitchen staff have consistently made sexually charged comments about how I look in my work uniform. I have told them that this is unacceptable behavior, but they have continued to do this, with no intervention from my manager.',\n",
       " 10: 'Given more responsibility in my role, but not more pay. I learned that my male coworker who was just hired was getting paid more for the same responsibilities, and when I brought this up to my manager, I was fired and banned from the premises.'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.6889528632164001,\n",
       " 2: 0.6368640065193176,\n",
       " 3: 0.569545567035675,\n",
       " 4: 0.6365067958831787,\n",
       " 10: 0.7169502377510071}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After disagreeing with my manager, I was taken aside and given a severance offer, while my male coworker who agreed with me was kept on the team'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df[\"Details\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given more responsibility in my role, but not more pay. I learned that my male coworker who was just hired was getting paid more for the same responsibilities, and when I brought this up to my manager, I was fired and banned from the premises.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df['Details'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>What happened?</th>\n",
       "      <th>Who is the employer?</th>\n",
       "      <th>Why do you believe this happened?</th>\n",
       "      <th>What Provice?</th>\n",
       "      <th>Details</th>\n",
       "      <th>Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>not_promoted</td>\n",
       "      <td>Airport or Airline</td>\n",
       "      <td>genetic</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Given more responsibility in my role, but not ...</td>\n",
       "      <td>Learned about my rights and consulted with a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unique ID What happened? Who is the employer?  \\\n",
       "10         10   not_promoted   Airport or Airline   \n",
       "\n",
       "   Why do you believe this happened? What Provice?  \\\n",
       "10                           genetic  Saskatchewan   \n",
       "\n",
       "                                              Details  \\\n",
       "10  Given more responsibility in my role, but not ...   \n",
       "\n",
       "                                           Resolution  \n",
       "10  Learned about my rights and consulted with a l...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df[archive_df[\"Unique ID\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
